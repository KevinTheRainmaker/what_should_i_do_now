import os
import asyncio
import json
from typing import Dict, Any, List, Optional
from pydantic import BaseModel
from openai import AsyncOpenAI
from dotenv import load_dotenv
from app.types.activity import Preferences, Context
from app.config import THEME_KEYWORDS, BUDGET_KEYWORDS, SEARCH_RADIUS

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class QuerySpec(BaseModel):
    q: str
    locale: str  # "es-ES", "ca-ES", "en"
    target: str  # "gmaps", "web"
    radius_meters: int

async def generate_llm_optimized_queries(preferences: Preferences, context: Context, location: str, radius: int = 1500) -> List[QuerySpec]:
    """LLMì„ ì‚¬ìš©í•´ ìì—°ì–´ ì…ë ¥ì„ í¬í•¨í•œ ìµœì í™”ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("   âš ï¸ OpenAI API í‚¤ê°€ ì—†ì–´ ê¸°ë³¸ ì¿¼ë¦¬ ìƒì„± ë°©ì‹ ì‚¬ìš©")
        return []
    
    try:
        client = AsyncOpenAI(api_key=api_key)
        
        # ì‚¬ìš©ì ì •ë³´ ì •ë¦¬
        themes_str = ", ".join([theme.value for theme in preferences.themes])
        budget_str = preferences.budget_level.value
        time_str = preferences.time_bucket.value
        natural_input = preferences.natural_input or ""
        
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ ë°”ë¥´ì…€ë¡œë‚˜ ê´€ê´‘ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” êµ¬ê¸€ë§µ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì •ë³´:**
- ë‚¨ì€ ì‹œê°„: {time_str}
- ì˜ˆì‚° ìˆ˜ì¤€: {budget_str}
- ê´€ì‹¬ í…Œë§ˆ: {themes_str}
- í˜„ì¬ ìœ„ì¹˜: {location}
- ì¶”ê°€ ìš”ì²­ì‚¬í•­: {natural_input if natural_input else "ì—†ìŒ"}

**ì¿¼ë¦¬ ìƒì„± ê·œì¹™:**
1. **í˜„ì¬ ìœ„ì¹˜ í™œìš© í•„ìˆ˜**: "{location}" ì£¼ë³€ì˜ ì¥ì†Œë¥¼ ê²€ìƒ‰ì–´ì— í¬í•¨
2. êµ¬ê¸€ë§µì—ì„œ ê²€ìƒ‰í•˜ê¸° ì¢‹ì€ í‚¤ì›Œë“œ ì‚¬ìš©
3. ì˜ì–´ì™€ ìŠ¤í˜ì¸ì–´ ì¿¼ë¦¬ ì¡°í•© (ê° ì–¸ì–´ë‹¹ 2-3ê°œ)
4. ì‚¬ìš©ìì˜ ì¶”ê°€ ìš”ì²­ì‚¬í•­ì„ í‚¤ì›Œë“œë¡œ ë°˜ì˜
5. í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê·¼ì²˜ ì¥ì†Œ ìš°ì„ 
6. ì´ 4-6ê°œì˜ ë‹¤ì–‘í•œ ì¿¼ë¦¬ ìƒì„±

**ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ ì˜ˆì‹œ:**
- "cafe near {location}" (í˜„ì¬ ìœ„ì¹˜ ê¸°ì¤€)
- "parque cerca de {location}" (í˜„ì¬ ìœ„ì¹˜ ê¸°ì¤€)
- "restaurant near {location}" (í˜„ì¬ ìœ„ì¹˜ ê¸°ì¤€)
- "quiet spot near {location}" (í˜„ì¬ ìœ„ì¹˜ ê¸°ì¤€)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "queries": [
    {{"query": "ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸", "language": "es", "explanation": "ì´ ì¿¼ë¦¬ë¥¼ ì„ íƒí•œ ì´ìœ "}},
    {{"query": "ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸", "language": "en", "explanation": "ì´ ì¿¼ë¦¬ë¥¼ ì„ íƒí•œ ì´ìœ "}}
  ]
}}

ì˜ˆì‹œ:
- ì¡°ìš©í•œ ì¹´í˜: "quiet cafe near {location}", "cafeteria tranquila cerca de {location}"
- ê³µì›: "park near {location}", "parque cerca de {location}"
- ì „ë§ëŒ€: "viewpoint near {location}", "mirador cerca de {location}"
"""

        response = await asyncio.wait_for(
            client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=500
            ),
            timeout=10.0
        )
        
        result = response.choices[0].message.content.strip()
        print(f"   ğŸ¤– LLM ì¿¼ë¦¬ ìƒì„± ì‘ë‹µ: {result[:200]}...")
        
        # JSON íŒŒì‹±
        try:
            query_data = json.loads(result)
            queries = []
            
            for item in query_data.get("queries", []):
                query_text = item.get("query", "")
                language = item.get("language", "en")
                explanation = item.get("explanation", "")
                
                if query_text:
                    locale = "es-ES" if language == "es" else "en"
                    queries.append(QuerySpec(
                        q=query_text,
                        locale=locale,
                        target="gmaps",
                        radius_meters=radius
                    ))
                    print(f"   ğŸ“ ìƒì„±ëœ ì¿¼ë¦¬ ({language}): {query_text}")
                    print(f"      ğŸ’­ ì´ìœ : {explanation}")
            
            return queries[:6]  # ìµœëŒ€ 6ê°œë¡œ ì œí•œ
            
        except json.JSONDecodeError as e:
            print(f"   âŒ LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
            
    except Exception as e:
        print(f"   âŒ LLM ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return []

def generate_search_queries(state: Dict[str, Any]) -> Dict[str, Any]:
    """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë…¸ë“œ"""
    print("[ì—ì´ì „íŠ¸] 2ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹œì‘")
    
    preferences: Preferences = state["preferences"]
    context: Context = state["context"]
    
    print(f"ì‚¬ìš©ì ì„ í˜¸:")
    print(f"ì‹œê°„: {preferences.time_bucket}")
    print(f"ì˜ˆì‚°: {preferences.budget_level}")
    print(f"í…Œë§ˆ: {[theme.value for theme in preferences.themes]}")
    print(f"ìì—°ì–´ ì…ë ¥: {preferences.natural_input}")
    
    queries = []
    
    # ì‹œê°„ ë²„í‚·ì— ë”°ë¥¸ ë°˜ê²½ ê²°ì •
    radius = SEARCH_RADIUS[preferences.time_bucket]
    print(f"ê²€ìƒ‰ ë°˜ê²½: {radius}m")
    
    # 1. LLM ê¸°ë°˜ ìµœì í™”ëœ ì¿¼ë¦¬ ìƒì„± ì‹œë„
    print("ğŸ¤– LLMìœ¼ë¡œ ë§ì¶¤í˜• ì¿¼ë¦¬ ìƒì„± ì¤‘...")
    try:
        import concurrent.futures
        
        def run_llm_query_generation():
            # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
            new_loop = asyncio.new_event_loop()
            asyncio.set_event_loop(new_loop)
            try:
                return new_loop.run_until_complete(
                    generate_llm_optimized_queries(preferences, context, context.location_label, radius)
                )
            finally:
                new_loop.close()
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(run_llm_query_generation)
            llm_queries = future.result(timeout=12)  # 12ì´ˆ íƒ€ì„ì•„ì›ƒ
            
        if llm_queries:
            print(f"âœ… LLMì—ì„œ {len(llm_queries)}ê°œ ë§ì¶¤í˜• ì¿¼ë¦¬ ìƒì„±ë¨")
            queries.extend(llm_queries)
        else:
            print("âš ï¸ LLM ì¿¼ë¦¬ ìƒì„± ê²°ê³¼ ì—†ìŒ")
            
    except Exception as e:
        print(f"âŒ LLM ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # 2. ê¸°ë³¸ í…Œë§ˆë³„ ì¿¼ë¦¬ë¡œ ë³´ì™„ (LLMì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ë¶€ì¡±í•  ë•Œ)
    if len(queries) < 3:
        print("ğŸ“ ê¸°ë³¸ í…Œë§ˆ ì¿¼ë¦¬ë¡œ ë³´ì™„ ì¤‘...")
        for theme in preferences.themes:
            theme_queries = generate_theme_queries(
                theme.value, 
                preferences.budget_level.value,
                context.location_label,
                radius
            )
            queries.extend(theme_queries)
            print(f"{theme.value}: {len(theme_queries)}ê°œ ì¿¼ë¦¬")
    
    # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 5ê°œë¡œ ì œí•œ
    unique_queries = []
    seen_queries = set()
    
    for query in queries:
        if query.q not in seen_queries and len(unique_queries) < 5:
            unique_queries.append(query)
            seen_queries.add(query.q)
    
    # ìµœì†Œ 2ê°œ ë³´ì¥
    if len(unique_queries) < 2:
        print("ì¿¼ë¦¬ ë¶€ì¡± - í´ë°± ì¿¼ë¦¬ ì¶”ê°€")
        fallback_queries = generate_fallback_queries(context.location_label, radius)
        unique_queries.extend(fallback_queries[:2])
    
    print(f"ìµœì¢… ê²€ìƒ‰ ì¿¼ë¦¬ {len(unique_queries)}ê°œ:")
    for i, query in enumerate(unique_queries, 1):
        print(f"{i}. '{query.q}' ({query.locale}, {query.target})")
    
    state["search_queries"] = unique_queries[:5]
    print("ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ\n")
    return state

def generate_theme_queries(theme: str, budget: str, location: str, radius: int) -> List[QuerySpec]:
    """í…Œë§ˆë³„ ì¿¼ë¦¬ ìƒì„±"""
    queries = []
    
    if theme in THEME_KEYWORDS:
        theme_words = THEME_KEYWORDS[theme]
        budget_words = BUDGET_KEYWORDS.get(budget, [""])
        
        # ìŠ¤í˜ì¸ì–´ ì¿¼ë¦¬
        if "es" in theme_words:
            for word in theme_words["es"][:2]:  # ìµœëŒ€ 2ê°œ
                budget_hint = budget_words[0] if budget_words else ""
                query_text = f"{word} cerca de {location} {budget_hint}".strip()
                queries.append(QuerySpec(
                    q=query_text,
                    locale="es-ES",
                    target="gmaps",
                    radius_meters=radius
                ))
        
        # ì˜ì–´ ì¿¼ë¦¬
        if "en" in theme_words and len(queries) < 3:
            for word in theme_words["en"][:1]:
                budget_hint = budget_words[1] if len(budget_words) > 1 else ""
                query_text = f"{word} near {location} {budget_hint}".strip()
                queries.append(QuerySpec(
                    q=query_text,
                    locale="en",
                    target="gmaps",
                    radius_meters=radius
                ))
    
    return queries

def generate_fallback_queries(location: str, radius: int) -> List[QuerySpec]:
    """í´ë°± ì¿¼ë¦¬ ìƒì„±"""
    return [
        QuerySpec(
            q=f"lugares interesantes cerca de {location}",
            locale="es-ES",
            target="gmaps",
            radius_meters=radius
        ),
        QuerySpec(
            q=f"things to do near {location}",
            locale="en",
            target="web",
            radius_meters=radius
        )
    ]
