import time
import os
import argparse
import uuid
from datetime import datetime
from typing import Dict, Any, List, Optional
from fastapi import FastAPI, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from pydantic import BaseModel
import json
import asyncio
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

from app.types.requests import RecommendRequest, RecommendResponse, HealthResponse
from app.types.activity import Preferences
from app.graph.companion_graph import companion_graph
from app.config import validate_env, update_default_context

# ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë¸ë“¤
class Question(BaseModel):
    id: str
    question: str
    answer: Optional[str] = None
    order: int

class QuestionAnswerPair(BaseModel):
    question: str
    answer: str
    order: int

class QuestionSession(BaseModel):
    session_id: str
    questions: List[Question]
    current_question_index: int = 0
    is_completed: bool = False
    created_at: datetime
    updated_at: datetime
    initial_preferences: Optional[Dict[str, Any]] = None

class QuestionRequest(BaseModel):
    session_id: str
    question_id: str
    answer: str

class QuestionResponse(BaseModel):
    session_id: str
    current_question: Optional[Question]
    is_completed: bool
    progress: int  # 0-100
    can_go_back: bool

# ì „ì—­ ì„¤ì • ë³€ìˆ˜ (argparseë¡œ ì„¤ì •ë¨)
CURRENT_LOCATION = "Centre de Convencions Internacional de Barcelona (CCIB)"
CURRENT_WEATHER = "â˜€ï¸ ë§‘ìŒ 24Â°C"
CURRENT_COORDS = {"lat": 41.4095, "lng": 2.2184}
CURRENT_WEATHER_CONDITION = "sunny"
CURRENT_TEMP = 24

# ì„¤ì •ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
app_config = {
    "location": "Centre de Convencions Internacional de Barcelona (CCIB)",
    "weather": "â˜€ï¸ ë§‘ìŒ 24Â°C",
    "coords": {"lat": 41.4095, "lng": 2.2184},
    "weather_condition": "sunny",
    "temp": 24
}

def format_weather_display(weather_condition: str, temp: int) -> str:
    """ë‚ ì”¨ ì¡°ê±´ê³¼ ì˜¨ë„ë¥¼ ì¡°í•©í•˜ì—¬ í‘œì‹œ ë¬¸ìì—´ ìƒì„±"""
    weather_emoji_map = {
        "sunny": "â˜€ï¸ ë§‘ìŒ",
        "cloudy": "â˜ï¸ íë¦¼",
        "rain": "ğŸŒ§ï¸ ë¹„",
        "windy": "ğŸ’¨ ë°”ëŒ",
        "unknown": "â“ ì•Œ ìˆ˜ ì—†ìŒ"
    }
    emoji_text = weather_emoji_map.get(weather_condition, "â“ ì•Œ ìˆ˜ ì—†ìŒ")
    return f"{emoji_text} {temp}Â°C"

# ì§ˆì˜ì‘ë‹µ ì„¸ì…˜ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬)
question_sessions: Dict[str, QuestionSession] = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    # ì‹œì‘ ì‹œ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    try:
        validate_env()
        print("âœ… Environment variables validated successfully")
    except ValueError as e:
        print(f"âŒ Environment validation failed: {e}")
        # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ê²½ê³ ë§Œ ì¶œë ¥
        if os.getenv("APP_ENV") != "development":
            raise
    
    # ì•± ì‹œì‘ ì‹œ í˜„ì¬ ì„¤ì • ì¶œë ¥
    print(f"ğŸš€ ì•± ì‹œì‘ ì‹œ ì„¤ì •: {app_config}")
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—…
    print("Application shutting down...")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="What should I do now?",
    description="ì—¬í–‰ìë¥¼ ìœ„í•œ í‚¬ë§íƒ€ì„ ì¶”ì²œ ì„œë¹„ìŠ¤",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš©, í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ (UIìš©)
app.mount("/static", StaticFiles(directory="static"), name="static")


@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return HealthResponse(
        status="ok",
        time=datetime.now().isoformat()
    )


@app.get("/api/context")
async def get_context():
    """í˜„ì¬ ìœ„ì¹˜ì™€ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    location = os.getenv("APP_LOCATION", app_config["location"])
    weather_condition = os.getenv("APP_WEATHER_CONDITION", app_config["weather_condition"])
    temp = int(os.getenv("APP_TEMP", str(app_config["temp"])))
    weather = os.getenv("APP_WEATHER", format_weather_display(weather_condition, temp))

    return {
        "location": location,
        "weather": weather,
        "coords": app_config["coords"],
        "weather_condition": app_config["weather_condition"],
        "temp": app_config["temp"]
    }


# ë…¸ë“œ ì´ë¦„ê³¼ ë‹¨ê³„ ë²ˆí˜¸ ë§¤í•‘
NODE_TO_STEP = {
    "initialize_context": 1,
    "generate_queries": 2,
    "search_and_normalize": 3,
    "filter_by_travel_time": 4,
    "classify_time": 5,
    "rank_activities": 6,
    "llm_evaluate": 7,
    "fetch_reviews": 8,
    "generate_fallback": 9
}

# ë‹¨ê³„ë³„ í…ìŠ¤íŠ¸
STEP_TEXTS = {
    1: "ğŸ”§ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ì¤‘...",
    2: "ğŸ¤– ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘...",
    3: "ğŸ” ì¥ì†Œ ê²€ìƒ‰ ë° ì •ê·œí™” ì¤‘...",
    4: "ğŸš— ì´ë™ì‹œê°„ í•„í„°ë§ ì¤‘...",
    5: "â° ì‹œê°„ ì í•©ë„ ë¶„ë¥˜ ì¤‘...",
    6: "ğŸ† í™œë™ ë­í‚¹ ì¤‘...",
    7: "ğŸ§  AI í‰ê°€ ë° ì„ ë³„ ì¤‘...",
    8: "ğŸ’¬ ë¦¬ë·° ìˆ˜ì§‘ ë° ìš”ì•½ ì¤‘...",
    9: "âœ¨ ìµœì¢… ê²°ê³¼ ìƒì„± ì¤‘..."
}

@app.post("/api/recommend/stream")
async def recommend_activities_stream(request: RecommendRequest):
    """í™œë™ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸ (SSE ìŠ¤íŠ¸ë¦¬ë°)"""
    
    async def event_generator():
        start_time = time.time()
        result = None
        
        try:
            print("=================================")
            print("[Gap-time Companion Agent ì‹œì‘]")
            print("=================================")
            print(f"ìš”ì²­: {request.preferences.time_bucket}, {request.preferences.budget_level}, {[t.value for t in request.preferences.themes]}")
            
            # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
            initial_state = {
                "preferences": request.preferences,
                "context_override": request.context_override or {},
                "start_time": start_time
            }
            
            # LangGraph ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
            print("\nLangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ (ìŠ¤íŠ¸ë¦¬ë°)...")
            
            async for event in companion_graph.astream_events(initial_state, version="v2"):
                event_type = event.get("event")
                node_name = event.get("name", "")
                
                # ë…¸ë“œ ì‹œì‘ ì´ë²¤íŠ¸
                if event_type == "on_chain_start" and node_name in NODE_TO_STEP:
                    step = NODE_TO_STEP[node_name]
                    text = STEP_TEXTS.get(step, f"{node_name} ì²˜ë¦¬ ì¤‘...")
                    
                    yield f"data: {json.dumps({'type': 'step_start', 'step': step, 'text': text, 'node': node_name})}\n\n"
                
                # ë…¸ë“œ ì™„ë£Œ ì´ë²¤íŠ¸
                elif event_type == "on_chain_end" and node_name in NODE_TO_STEP:
                    step = NODE_TO_STEP[node_name]
                    
                    yield f"data: {json.dumps({'type': 'step_complete', 'step': step, 'node': node_name})}\n\n"
                    
                    # ìµœì¢… ê²°ê³¼ ì €ì¥ (ë§ˆì§€ë§‰ ë…¸ë“œ ì™„ë£Œ ì‹œ)
                    if node_name == "generate_fallback":
                        # ìµœì¢… ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                        if "data" in event and "output" in event["data"]:
                            result = event["data"]["output"]
                        elif "data" in event and isinstance(event["data"], dict):
                            result = event["data"]
            
            # ìµœì¢… ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²´ ê·¸ë˜í”„ ì‹¤í–‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            if not result:
                print("   âš ï¸ ì´ë²¤íŠ¸ì—ì„œ ìµœì¢… ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - ì „ì²´ ì‹¤í–‰ìœ¼ë¡œ ëŒ€ì²´")
                result = await companion_graph.ainvoke(initial_state)
            
            # ìµœì¢… ê²°ê³¼ ì „ì†¡
            if result:
                end_time = time.time()
                latency_ms = int((end_time - start_time) * 1000)
                
                print("=================================")
                print("[ìµœì¢… ê²°ê³¼ ìš”ì•½]")
                print("=================================")
                print(f"ì´ ì†Œìš”ì‹œê°„: {latency_ms}ms")
                print(f"ê²€ìƒ‰ í†µê³„: {result.get('source_stats', {})}")
                print(f"í´ë°± ì‚¬ìš©: {'ì˜ˆ' if result.get('fallback_used', False) else 'ì•„ë‹ˆì˜¤'}")
                print(f"ìµœì¢… ì¶”ì²œ: {len(result['ranked_items'])}ê°œ")
                for i, item in enumerate(result['ranked_items'], 1):
                    print(f"   {i}. {item.name} ({item.total_score:.1f}ì )")
                print("=================================\n")
                
                # LLM í‰ê°€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ê²°ê³¼ ì‚¬ìš©
                final_items = result.get("llm_selected_items", result["ranked_items"])
                
                # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜
                def to_dict(obj):
                    if hasattr(obj, "dict"):
                        return obj.dict()
                    elif hasattr(obj, "__dict__"):
                        return {k: to_dict(v) for k, v in obj.__dict__.items()}
                    elif isinstance(obj, list):
                        return [to_dict(item) for item in obj]
                    elif isinstance(obj, dict):
                        return {k: to_dict(v) for k, v in obj.items()}
                    else:
                        return obj
                
                response_data = {
                    "session_id": result.get("session_id", ""),
                    "context": to_dict(result.get("context", {})),
                    "items": [to_dict(item) for item in final_items],
                    "meta": {
                        "latencyMs": latency_ms,
                        "sourceStats": result.get("source_stats", {}),
                        "fallbackUsed": result.get("fallback_used", False),
                        "llmEvaluated": "llm_selected_items" in result,
                        "llmEvaluation": result.get("llm_evaluation", "")
                    }
                }
                
                yield f"data: {json.dumps({'type': 'result', 'data': response_data})}\n\n"
            else:
                yield f"data: {json.dumps({'type': 'error', 'message': 'ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})}\n\n"
                
        except Exception as e:
            import traceback
            error_details = {
                "error_type": type(e).__name__,
                "error_message": str(e),
                "traceback": traceback.format_exc()
            }
            
            print(f"âŒ CRITICAL ERROR in recommend_activities_stream:")
            print(f"   Error Type: {error_details['error_type']}")
            print(f"   Error Message: {error_details['error_message']}")
            print(f"   Full Traceback:")
            print(error_details['traceback'])
            
            try:
                yield f"data: {json.dumps({'type': 'error', 'message': 'ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.', 'error_type': error_details['error_type']})}\n\n"
            except:
                pass  # ìŠ¤íŠ¸ë¦¼ì´ ì´ë¯¸ ë‹«í˜”ì„ ìˆ˜ ìˆìŒ
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

@app.post("/api/recommend", response_model=RecommendResponse)
async def recommend_activities(request: RecommendRequest):
    """í™œë™ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    
    start_time = time.time()
    
    try:
        print("=================================")
        print("[Gap-time Companion Agent ì‹œì‘]")
        print("=================================")
        print(f"ìš”ì²­: {request.preferences.time_bucket}, {request.preferences.budget_level}, {[t.value for t in request.preferences.themes]}")
        
        # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
        initial_state = {
            "preferences": request.preferences,
            "context_override": request.context_override or {},
            "start_time": start_time
        }
        
        # LangGraph ì‹¤í–‰
        print("\nLangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...")
        result = await companion_graph.ainvoke(initial_state)
        
        # ì‘ë‹µ ìƒì„±
        end_time = time.time()
        latency_ms = int((end_time - start_time) * 1000)
        
        print("=================================")
        print("[ìµœì¢… ê²°ê³¼ ìš”ì•½]")
        print("=================================")
        print(f"ì´ ì†Œìš”ì‹œê°„: {latency_ms}ms")
        print(f"ê²€ìƒ‰ í†µê³„: {result.get('source_stats', {})}")
        print(f"í´ë°± ì‚¬ìš©: {'ì˜ˆ' if result.get('fallback_used', False) else 'ì•„ë‹ˆì˜¤'}")
        print(f"ìµœì¢… ì¶”ì²œ: {len(result['ranked_items'])}ê°œ")
        for i, item in enumerate(result['ranked_items'], 1):
            print(f"   {i}. {item.name} ({item.total_score:.1f}ì )")
        print("=================================\n")
        
        # LLM í‰ê°€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ê²°ê³¼ ì‚¬ìš©
        final_items = result.get("llm_selected_items", result["ranked_items"])
        
        response = RecommendResponse(
            session_id=result["session_id"],
            context=result["context"],
            items=final_items,
            meta={
                "latencyMs": latency_ms,
                "sourceStats": result.get("source_stats", {}),
                "fallbackUsed": result.get("fallback_used", False),
                "llmEvaluated": "llm_selected_items" in result,
                "llmEvaluation": result.get("llm_evaluation", "")
            }
        )
        
        return response
        
    except Exception as e:
        import traceback
        error_details = {
            "error_type": type(e).__name__,
            "error_message": str(e),
            "traceback": traceback.format_exc()
        }
        
        print(f"âŒ CRITICAL ERROR in recommend_activities:")
        print(f"   Error Type: {error_details['error_type']}")
        print(f"   Error Message: {error_details['error_message']}")
        print(f"   Full Traceback:")
        print(error_details['traceback'])
        
        # ì‚¬ìš©ìì—ê²ŒëŠ” ê°„ë‹¨í•œ ë©”ì‹œì§€, ê°œë°œìì—ê²ŒëŠ” ìƒì„¸ ì •ë³´
        raise HTTPException(
            status_code=500,
            detail={
                "message": "ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "error_type": error_details['error_type'],
                "timestamp": datetime.now().isoformat()
            }
        )


# ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ APIë“¤
class QuestionStartRequest(BaseModel):
    time_bucket: Optional[str] = None
    budget_level: Optional[str] = None
    themes: Optional[str] = None

@app.post("/api/questions/start")
async def start_question_session(request: QuestionStartRequest):
    """ìƒˆë¡œìš´ ì§ˆì˜ì‘ë‹µ ì„¸ì…˜ ì‹œì‘ - ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ ìƒì„±"""
    session_id = str(uuid.uuid4())

    # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘
    current_location = os.getenv("APP_LOCATION", "Barcelona")
    current_weather_condition = os.getenv("APP_WEATHER_CONDITION", "sunny")
    current_temp = int(os.getenv("APP_TEMP", "24"))
    current_weather = os.getenv("APP_WEATHER", format_weather_display(current_weather_condition, current_temp))

    user_time = request.time_bucket if request else None
    user_budget = request.budget_level if request else None
    user_themes = request.themes if request else None

    # ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ ìƒì„±
    first_question = await generate_first_question(
        location=current_location,
        weather=current_weather,
        temperature=current_temp,
        weather_condition=current_weather_condition,
        user_time=user_time,
        user_budget=user_budget,
        user_themes=user_themes
    )

    initial_preferences = {
        "time_bucket": request.time_bucket,
        "budget_level": request.budget_level,
        "themes": [request.themes]
    }
    
    session = QuestionSession(
        session_id=session_id,
        questions=[first_question],  # ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ ì €ì¥
        current_question_index=0,
        is_completed=False,
        created_at=datetime.now(),
        updated_at=datetime.now(),
        initial_preferences=initial_preferences
    )

    question_sessions[session_id] = session

    return QuestionResponse(
        session_id=session_id,
        current_question=first_question,
        is_completed=False,
        progress=0,
        can_go_back=False
    )

async def generate_first_question(location: str, weather: str, temperature: str, weather_condition: str,
                                  user_time: str = None, user_budget: str = None, user_themes: str = None) -> Question:
    """ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜)"""
    import openai
    from openai import AsyncOpenAI

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.error("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return Exception("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê°œë°œìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.")

    try:
        client = AsyncOpenAI(api_key=api_key)

        # ì‚¬ìš©ì ì„ íƒ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        user_info = ""
        if user_time or user_budget or user_themes:
            user_info = "\n**ì‚¬ìš©ì ì„ íƒ ì •ë³´:**\n"
            if user_time:
                user_info += f"- ì„ íƒí•œ ì‹œê°„: {user_time}\n"
            if user_budget:
                user_info += f"- ì„ íƒí•œ ì˜ˆì‚°: {user_budget}\n"
            if user_themes:
                user_info += f"- ì„ íƒí•œ í…Œë§ˆ: {user_themes}\n"

        prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì—¬í–‰ì§€ íƒìƒ‰ì„ ë•ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:**
- ìœ„ì¹˜: {location}
- ë‚ ì”¨: {format_weather_display(weather_condition, temperature)}
- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¥ì†Œ í…Œë§ˆ: {user_themes}

**ì§ˆë¬¸ ìƒì„± ê·œì¹™:**
1. ì‚¬ìš©ì ì„ í˜¸ ì¥ì†Œ í…Œë§ˆì— ë§ì¶°, ì ì ˆí•œ ì¥ì†Œë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•œ ì˜ˆë¹„ ì§ˆë¬¸ì„ ìƒì„±
2. ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆëŠ” ë„›ì§€í˜• ì§ˆë¬¸ì„ ìƒì„±
3. ì‚¬ìš©ìê°€ ì´ë¯¸ ì„ íƒí•œ ì •ë³´ëŠ” ì¤‘ë³µ ì§ˆë¬¸í•˜ì§€ ë§ê³ , ë” êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì„ ë¬»ëŠ” ì§ˆë¬¸ ìƒì„±

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "question": "ì§ˆë¬¸ ë‚´ìš©"
}}"""

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì—¬í–‰ì§€ íƒìƒ‰ì„ ë•ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=200
        )

        result = response.choices[0].message.content.strip()
        logger.info(f"LLM ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‘ë‹µ: {result}")

        # JSON íŒŒì‹± 
        try:
            # ```json ``` ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
            if "```json" in result:
                json_start = result.find("```json") + 7
                json_end = result.find("```", json_start)
                json_content = result[json_start:json_end].strip()
            elif "```" in result:
                json_start = result.find("```") + 3
                json_end = result.find("```", json_start)
                json_content = result[json_start:json_end].strip()
            else:
                json_content = result
            
            data = json.loads(json_content)
            question_text = data.get("question", "")
            
            if question_text:
                return Question(
                    id=str(uuid.uuid4()),
                    question=question_text,
                    order=1
                )
            else:
                logger.error(f"ì§ˆë¬¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                return Exception(f"ì§ˆë¬¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        except json.JSONDecodeError as e:
            logger.error(f"LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"íŒŒì‹± ì‹¤íŒ¨í•œ ì‘ë‹µ: {result}")
            return Exception(f"LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

    except Exception as e:
        logger.error(f"LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return Exception(f"LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")


async def generate_next_question(location: str, weather: str, temperature: str, weather_condition: str,
                                  previous_qa: List[QuestionAnswerPair], question_number: int,
                                  user_time: str = None, user_budget: str = None, user_themes: str = None) -> Question:
    """ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±"""
    from openai import AsyncOpenAI

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.error("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return Exception("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê°œë°œìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.")
    try:
        client = AsyncOpenAI(api_key=api_key)

        # ì´ì „ ì§ˆë¬¸-ë‹µë³€ í˜ì–´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        qa_history = "\n**ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€:**\n"
        for qa in previous_qa:
            qa_history += f"Q{qa.order}: {qa.question}\nA{qa.order}: {qa.answer}\n\n"

        # ì‚¬ìš©ì ì„ íƒ ì •ë³´
        user_info = ""
        if user_time or user_budget or user_themes:
            user_info = "\n**ì‚¬ìš©ì ì„ íƒ ì •ë³´:**\n"
            if user_time:
                user_info += f"- ì„ íƒí•œ ë‚¨ì€ ì‹œê°„: {user_time}\n"
            if user_budget:
                user_info += f"- ì„ íƒí•œ ì˜ˆì‚° ìˆ˜ì¤€: {user_budget}\n"
            if user_themes:
                user_info += f"- ì„ íƒí•œ ì¥ì†Œ í…Œë§ˆ: {user_themes}\n"

        # ì§ˆë¬¸ ë²ˆí˜¸ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if question_number == 2:
            # ë‘ ë²ˆì§¸ ì§ˆë¬¸: íƒìƒ‰ì  ì§ˆë¬¸, ë²”ìœ„ë¥¼ ë„“íˆëŠ” ì§ˆë¬¸
            prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì—¬í–‰ì§€ íƒìƒ‰ì„ ë•ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê³ ë ¤í•˜ì—¬ ë‘ ë²ˆì§¸ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:**
- ìœ„ì¹˜: {location}
- ë‚ ì”¨: {format_weather_display(weather_condition, temperature)}
- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¥ì†Œ í…Œë§ˆ: {user_themes}

**ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€:**
{qa_history}

**ì§ˆë¬¸ ìƒì„± ê·œì¹™ (ë‘ ë²ˆì§¸ ì§ˆë¬¸ - íƒìƒ‰ ë‹¨ê³„):**
1. ì²« ë²ˆì§¸ ì§ˆë¬¸ì—ì„œ ë‹¤ë£¨ì§€ ì•Šì€ ìƒˆë¡œìš´ ì¸¡ë©´ì´ë‚˜ ê´€ì ì„ íƒìƒ‰í•˜ëŠ” ì§ˆë¬¸ì„ ìƒì„±
2. ì‚¬ìš©ìì˜ ì„ í˜¸ë„ ë²”ìœ„ë¥¼ ë„“íˆê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì˜µì…˜ì„ ì œì‹œí•˜ê±°ë‚˜, ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë‚˜ íŠ¹ì„±ì„ íƒìƒ‰í•  ìˆ˜ ìˆë„ë¡ ìœ ë„
3. ì˜ˆë¥¼ ë“¤ì–´, í™œë™ ìœ í˜•, ë¶„ìœ„ê¸°, ê²½í—˜ ë°©ì‹, íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­ ë“± ìƒˆë¡œìš´ ì°¨ì›ì„ íƒìƒ‰
4. ì‚¬ìš©ìê°€ ì´ë¯¸ ì„ íƒí•œ ì •ë³´ëŠ” ì¤‘ë³µ ì§ˆë¬¸í•˜ì§€ ë§ê³ , ë” ë„“ì€ ë²”ìœ„ì˜ ì„ í˜¸ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ìƒì„±
5. ë‹¨, í˜„ì¬ ì»¨í…ìŠ¤íŠ¸(ìœ„ì¹˜, ë‚ ì”¨, í…Œë§ˆ)ì—ì„œ ë²—ì–´ë‚˜ë©´ ì•ˆë¨

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "question": "ì§ˆë¬¸ ë‚´ìš©"
}}"""
        elif question_number == 3:
            # ì„¸ ë²ˆì§¸ ì§ˆë¬¸: ë²”ìœ„ë¥¼ ì¢íˆê³  ë””í…Œì¼ì„ ì¶”ê°€í•˜ëŠ” ì§ˆë¬¸
            prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì—¬í–‰ì§€ íƒìƒ‰ì„ ë•ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì´ì „ ë‘ ê°œì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì„¸ ë²ˆì§¸ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:**
- ìœ„ì¹˜: {location}
- ë‚ ì”¨: {format_weather_display(weather_condition, temperature)}
- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¥ì†Œ í…Œë§ˆ: {user_themes}

**ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€:**
{qa_history}

**ì§ˆë¬¸ ìƒì„± ê·œì¹™ (ì„¸ ë²ˆì§¸ ì§ˆë¬¸ - êµ¬ì²´í™” ë‹¨ê³„):**
1. ì´ì „ ë‘ ê°œì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬, ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ êµ¬ì²´í™”í•˜ê³  ë””í…Œì¼ì„ ì¶”ê°€í•˜ëŠ” ì§ˆë¬¸ì„ ìƒì„±
2. ë²”ìœ„ë¥¼ ì¢í˜€ì„œ ë” êµ¬ì²´ì ì´ê³  ì„¸ë°€í•œ ì„ í˜¸ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìœ ë„
3. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ë¶„ìœ„ê¸°, ê°€ê²©ëŒ€, í™œë™ ê°•ë„, ì†Œìš” ì‹œê°„, ì ‘ê·¼ì„± ë“± êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì„ ë¬»ëŠ” ì§ˆë¬¸
4. ì´ì „ ë‹µë³€ì—ì„œ ì–¸ê¸‰ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ë” ê¹Šì´ ìˆëŠ” ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” í›„ì† ì§ˆë¬¸ ìƒì„±
5. ìµœì¢…ì ìœ¼ë¡œ ì í•©í•œ ì¥ì†Œë¥¼ ì¶”ì²œí•˜ê¸° ìœ„í•´ í•„ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì§ˆë¬¸

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "question": "ì§ˆë¬¸ ë‚´ìš©"
}}"""

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì—¬í–‰ì§€ íƒìƒ‰ì„ ë•ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=200
        )

        result = response.choices[0].message.content.strip()
        logger.info(f"LLM {question_number}ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‘ë‹µ: {result}")

        # JSON íŒŒì‹± 
        try:
            # ```json ``` ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
            if "```json" in result:
                json_start = result.find("```json") + 7
                json_end = result.find("```", json_start)
                json_content = result[json_start:json_end].strip()
            elif "```" in result:
                json_start = result.find("```") + 3
                json_end = result.find("```", json_start)
                json_content = result[json_start:json_end].strip()
            else:
                json_content = result
            
            data = json.loads(json_content)
            question_text = data.get("question", "")
            
            if question_text:
                return Question(
                    id=str(uuid.uuid4()),
                    question=question_text,
                    order=question_number
                )
            else:
                logger.error(f"ì§ˆë¬¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                return Exception(f"ì§ˆë¬¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        except json.JSONDecodeError as e:
            logger.error(f"LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"íŒŒì‹± ì‹¤íŒ¨í•œ ì‘ë‹µ: {result}")
            return Exception(f"LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")   
    except Exception as e:
        logger.error(f"LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return Exception(f"LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")


# async def generate_contextual_questions(location: str, weather: str, temperature: str, weather_condition: str,
#                                        user_time: str = None, user_budget: str = None, user_themes: str = None) -> List[Question]:
#     """í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì§ˆë¬¸ì„ ë™ì ìœ¼ë¡œ ìƒì„±"""
#     import openai
#     from openai import AsyncOpenAI
    
#     api_key = os.getenv("OPENAI_API_KEY")
#     if not api_key:
#         logger.error("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return Exception("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê°œë°œìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.")
#         return get_default_questions(location, weather, user_time, user_budget, user_themes)
    
#     try:
#         client = AsyncOpenAI(api_key=api_key)
        
#         # ì‚¬ìš©ì ì„ íƒ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
#         user_info = ""
#         if user_time or user_budget or user_themes:
#             user_info = "\n**ì‚¬ìš©ì ì„ íƒ ì •ë³´:**\n"
#             if user_time:
#                 user_info += f"- ì„ íƒí•œ ì‹œê°„: {user_time}\n"
#             if user_budget:
#                 user_info += f"- ì„ íƒí•œ ì˜ˆì‚°: {user_budget}\n"
#             if user_themes:
#                 user_info += f"- ì„ íƒí•œ í…Œë§ˆ: {user_themes}\n"
        
#         prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì—¬í–‰ì§€ íƒìƒ‰ì„ ë•ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ 3ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

# **í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:**
# - ìœ„ì¹˜: {location}
# - ë‚ ì”¨: {format_weather_display(weather_condition, temperature)}
# - ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¥ì†Œ í…Œë§ˆ: {user_themes}

# **ì§ˆë¬¸ ìƒì„± ê·œì¹™:**
# 1. í˜„ì¬ ìœ„ì¹˜ì™€ ë‚ ì”¨ë¥¼ ê³ ë ¤í•œ ì§ˆë¬¸
# 2. ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ì„ í˜¸ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸
# 3. ê° ì§ˆë¬¸ì€ ì„œë¡œ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë‹¤ë¤„ì•¼ í•¨ (í™œë™ ìœ í˜•, ë¶„ìœ„ê¸°, íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­ ë“±)
# 4. ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ì„±
# 5. êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ í•¨
# 6. ì‚¬ìš©ìê°€ ì´ë¯¸ ì„ íƒí•œ ì •ë³´ëŠ” ì¤‘ë³µ ì§ˆë¬¸í•˜ì§€ ë§ê³ , ë” êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì„ ë¬»ëŠ” ì§ˆë¬¸ ìƒì„±

# ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
# {{
#   "questions": [
#     {{
#       "question": "ì§ˆë¬¸ ë‚´ìš©",
#       "order": 1
#     }},
#     {{
#       "question": "ì§ˆë¬¸ ë‚´ìš©", 
#       "order": 2
#     }},
#     {{
#       "question": "ì§ˆë¬¸ ë‚´ìš©",
#       "order": 3
#     }}
#   ]
# }}"""

#         response = await client.chat.completions.create(
#             model="gpt-4o-mini",
#             messages=[
#                 {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬í–‰ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
#                 {"role": "user", "content": prompt}
#             ],
#             temperature=0.7,
#             max_tokens=500
#         )
        
#         result = response.choices[0].message.content.strip()
#         print(f"ğŸ¤– LLM ì§ˆë¬¸ ìƒì„± ì‘ë‹µ: {result[:200]}...")
        
#         # JSON íŒŒì‹±
#         import json
#         try:
#             data = json.loads(result)
#             questions = []
            
#             for item in data.get("questions", []):
#                 question = Question(
#                     id=str(uuid.uuid4()),
#                     question=item.get("question", ""),
#                     order=item.get("order", 1)
#                 )
#                 questions.append(question)
            
#             # ìˆœì„œëŒ€ë¡œ ì •ë ¬
#             questions.sort(key=lambda x: x.order)
#             return questions[:3]  # ìµœëŒ€ 3ê°œ
            
#         except json.JSONDecodeError as e:
#             print(f"âŒ LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
#             return get_default_questions(location, weather)
            
#     except Exception as e:
#         print(f"âŒ LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
#         return get_default_questions(location, weather)






@app.post("/api/questions/answer", response_model=QuestionResponse)
async def answer_question(request: QuestionRequest):
    """ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±"""
    if request.session_id not in question_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    session = question_sessions[request.session_id]

    # í˜„ì¬ ì§ˆë¬¸ì— ë‹µë³€ ì €ì¥
    for question in session.questions:
        if question.id == request.question_id:
            question.answer = request.answer
            break

    # ë‹¤ìŒ ì§ˆë¬¸ ë²ˆí˜¸ ê³„ì‚°
    next_question_number = len(session.questions) + 1

    # ì´ 3ê°œ ì§ˆë¬¸ì´ë©´ ì™„ë£Œ
    if next_question_number > 3:
        session.is_completed = True
        session.updated_at = datetime.now()
        return QuestionResponse(
            session_id=session.session_id,
            current_question=None,
            is_completed=True,
            progress=100,
            can_go_back=True
        )

    # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    current_location = os.getenv("APP_LOCATION", "Barcelona")
    current_weather_condition = os.getenv("APP_WEATHER_CONDITION", "sunny")
    current_temp = int(os.getenv("APP_TEMP", "24"))
    current_weather = os.getenv("APP_WEATHER", format_weather_display(current_weather_condition, current_temp))

    # ì´ì „ ì§ˆë¬¸-ë‹µë³€ í˜ì–´ ìƒì„±
    previous_qa = []
    for q in session.questions:
        if q.answer:
            previous_qa.append(QuestionAnswerPair(
                question=q.question,
                answer=q.answer,
                order=q.order
            ))

    # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± (ì´ì „ ë‹µë³€ ê¸°ë°˜)
    next_question = await generate_next_question(
        location=current_location,
        weather=current_weather,
        temperature=current_temp,
        weather_condition=current_weather_condition,
        previous_qa=previous_qa,
        question_number=next_question_number
    )

    # ì„¸ì…˜ì— ì§ˆë¬¸ ì¶”ê°€
    session.questions.append(next_question)
    session.current_question_index = len(session.questions) - 1
    session.updated_at = datetime.now()

    # ì§„í–‰ë¥  ê³„ì‚° (3ê°œ ì§ˆë¬¸ ê¸°ì¤€)
    progress = int((next_question_number - 1) / 3 * 100)

    return QuestionResponse(
        session_id=session.session_id,
        current_question=next_question,
        is_completed=False,
        progress=progress,
        can_go_back=True
    )

@app.post("/api/questions/back")
async def go_back_question(session_id: str):
    """ì´ì „ ì§ˆë¬¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°"""
    if session_id not in question_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    session = question_sessions[session_id]
    
    if session.current_question_index > 0:
        session.current_question_index -= 1
        session.updated_at = datetime.now()
    
    current_question = session.questions[session.current_question_index]
    progress = int((session.current_question_index / len(session.questions)) * 100)
    
    return QuestionResponse(
        session_id=session.session_id,
        current_question=current_question,
        is_completed=False,
        progress=progress,
        can_go_back=session.current_question_index > 0
    )

@app.get("/api/questions/{session_id}")
async def get_question_session(session_id: str):
    """ì§ˆì˜ì‘ë‹µ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    if session_id not in question_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    session = question_sessions[session_id]
    current_question = session.questions[session.current_question_index] if not session.is_completed else None
    progress = int((session.current_question_index / len(session.questions)) * 100)
    
    return QuestionResponse(
        session_id=session.session_id,
        current_question=current_question,
        is_completed=session.is_completed,
        progress=progress,
        can_go_back=session.current_question_index > 0
    )

@app.post("/api/questions/{session_id}/recommend", response_model=RecommendResponse)
async def get_recommendations_from_questions(session_id: str):
    """ì§ˆì˜ì‘ë‹µ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ìƒì„±"""
    if session_id not in question_sessions:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    session = question_sessions[session_id]
    
    if not session.is_completed:
        raise HTTPException(status_code=400, detail="ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    # ì§ˆì˜ì‘ë‹µ ê²°ê³¼ë¥¼ Preferencesë¡œ ë³€í™˜
    preferences = convert_question_answers_to_preferences(session)
    
    # ê¸°ì¡´ ì¶”ì²œ ì‹œìŠ¤í…œ í˜¸ì¶œ
    try:
        start_time = time.time()
        
        initial_state = {
            "preferences": preferences,
            "context_override": None
        }
        
        result = await companion_graph.ainvoke(initial_state)
        
        latency_ms = int((time.time() - start_time) * 1000)
        
        # LLM í‰ê°€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ê²°ê³¼ ì‚¬ìš©
        final_items = result.get("llm_selected_items", result["ranked_items"])
        
        response = RecommendResponse(
            session_id=result["session_id"],
            context=result["context"],
            items=final_items,
            meta={
                "latencyMs": latency_ms,
                "sourceStats": result.get("source_stats", {}),
                "fallbackUsed": result.get("fallback_used", False),
                "llmEvaluated": "llm_selected_items" in result,
                "llmEvaluation": result.get("llm_evaluation", ""),
                "questionSessionId": session_id
            }
        )
        
        return response
        
    except Exception as e:
        import traceback
        error_details = {
            "error_type": type(e).__name__,
            "error_message": str(e),
            "traceback": traceback.format_exc()
        }
        
        print(f"âŒ CRITICAL ERROR in get_recommendations_from_questions:")
        print(f"   Error Type: {error_details['error_type']}")
        print(f"   Error Message: {error_details['error_message']}")
        
        raise HTTPException(
            status_code=500,
            detail={
                "message": "ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "error_type": error_details['error_type'],
                "timestamp": datetime.now().isoformat()
            }
        )

def convert_question_answers_to_preferences(session: QuestionSession) -> Preferences:
    """ì§ˆì˜ì‘ë‹µ ê²°ê³¼ë¥¼ Preferences ê°ì²´ë¡œ ë³€í™˜"""
    # ì§ˆë¬¸-ì‘ë‹µ í˜ì–´ ìƒì„±
    question_answer_pairs = []
    for question in session.questions:
        if question.answer:
            question_answer_pairs.append(QuestionAnswerPair(
                question=question.question,
                answer=question.answer,
                order=question.order
            ))
    
    # ì§ˆë¬¸-ì‘ë‹µ í˜ì–´ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜
    natural_input = ""
    for pair in sorted(question_answer_pairs, key=lambda x: x.order):
        natural_input += f"Q: {pair.question} A: {pair.answer} "
    
    initial_prefs = session.initial_preferences
    
    from app.types.activity import TimeBucket, PriceLevel, Theme
    
    return Preferences(
        time_bucket=TimeBucket(initial_prefs["time_bucket"]),
        budget_level=PriceLevel(initial_prefs["budget_level"]),
        themes=[Theme(theme) for theme in initial_prefs["themes"]],
        natural_input=natural_input.strip()
    )


@app.get("/", response_class=HTMLResponse)
async def serve_ui():
    """ë©”ì¸ UI í˜ì´ì§€ ì„œë¹™"""
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°
    location = os.getenv("APP_LOCATION", app_config["location"])
    weather_condition = os.getenv("APP_WEATHER_CONDITION", app_config["weather_condition"])
    temp = int(os.getenv("APP_TEMP", str(app_config["temp"])))
    weather = os.getenv("APP_WEATHER", format_weather_display(weather_condition, temp))

    print(f"ğŸ“ ìœ„ì¹˜: {location}")
    print(f"ğŸŒ¤ï¸ ë‚ ì”¨: {weather}")

    # static/index.html íŒŒì¼ ì½ê¸°
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            html_content = f.read()

        return HTMLResponse(content=html_content)
    except FileNotFoundError:
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
        return HTMLResponse(
            content="""
            <html>
            <body>
                <h1>Error: static/index.html not found</h1>
                <p>Please make sure the static files are properly set up.</p>
            </body>
            </html>
            """,
            status_code=500
        )


if __name__ == "__main__":
    import uvicorn
    
    # argparse ì„¤ì •
    parser = argparse.ArgumentParser(description="What should I do now? - ì—¬í–‰ìë¥¼ ìœ„í•œ í‚¬ë§íƒ€ì„ ì¶”ì²œ ì„œë¹„ìŠ¤")
    parser.add_argument("--location", type=str, default="Centre de Convencions Internacional de Barcelona (CCIB)", 
                       help="í˜„ì¬ ìœ„ì¹˜ (ê¸°ë³¸ê°’: CCIB)")
    parser.add_argument("--lat", type=float, default=41.4095, 
                       help="ìœ„ë„ (ê¸°ë³¸ê°’: 41.4095)")
    parser.add_argument("--lng", type=float, default=2.2184, 
                       help="ê²½ë„ (ê¸°ë³¸ê°’: 2.2184)")
    parser.add_argument("--weather-condition", type=str, default="sunny", 
                       choices=["sunny", "cloudy", "rain", "windy", "unknown"],
                       help="ë‚ ì”¨ ì¡°ê±´ (ê¸°ë³¸ê°’: sunny)")
    parser.add_argument("--temp", type=int, default=24, 
                       help="ì˜¨ë„ (ì„­ì”¨, ê¸°ë³¸ê°’: 24)")
    parser.add_argument("--port", type=int, default=8000, 
                       help="ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 8000)")
    parser.add_argument("--host", type=str, default="0.0.0.0", 
                       help="ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 0.0.0.0)")
    
    args = parser.parse_args()
    
    # ë‚ ì”¨ í‘œì‹œ ë¬¸ìì—´ ìƒì„±
    weather_display = format_weather_display(args.weather_condition, args.temp)
    
    # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
    CURRENT_LOCATION = args.location
    CURRENT_WEATHER = weather_display
    CURRENT_COORDS = {"lat": args.lat, "lng": args.lng}
    CURRENT_WEATHER_CONDITION = args.weather_condition
    CURRENT_TEMP = args.temp
    
    # app_config ì—…ë°ì´íŠ¸
    app_config["location"] = args.location
    app_config["weather"] = weather_display
    app_config["coords"] = {"lat": args.lat, "lng": args.lng}
    app_config["weather_condition"] = args.weather_condition
    app_config["temp"] = args.temp
    
    # í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • (FastAPIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)
    os.environ["APP_LOCATION"] = args.location
    os.environ["APP_WEATHER"] = weather_display
    os.environ["APP_WEATHER_CONDITION"] = args.weather_condition
    os.environ["APP_TEMP"] = str(args.temp)
    os.environ["APP_LAT"] = str(args.lat)
    os.environ["APP_LNG"] = str(args.lng)
    
    print(f"DEBUG: app_config ì—…ë°ì´íŠ¸ í›„ = {app_config}")
    print(f"DEBUG: í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ")
    
    # config.pyì˜ DEFAULT_CONTEXT ì—…ë°ì´íŠ¸
    update_default_context(
        location_label=args.location,
        lat=args.lat,
        lng=args.lng,
        weather_condition=args.weather_condition,
        temp_c=args.temp
    )
    
    print(f"ğŸŒ ìœ„ì¹˜: {CURRENT_LOCATION}")
    print(f"ğŸ“ ì¢Œí‘œ: {CURRENT_COORDS['lat']}, {CURRENT_COORDS['lng']}")
    print(f"ğŸŒ¤ï¸ ë‚ ì”¨: {CURRENT_WEATHER_CONDITION} {CURRENT_TEMP}Â°C")
    print(f"ğŸŒ ì„œë²„: {args.host}:{args.port}")
    
    uvicorn.run(
        "main:app", 
        host=args.host, 
        port=args.port, 
        reload=True,
        log_level="info"
    )
